"""
æŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰ç« èŠ‚ç”Ÿæˆå·¥å…·
"""

import logging
from typing import Dict, Any, Annotated, Optional

from llama_index.core import Settings
from llama_index.core.llms import ChatMessage
from models.report_models import ProfitForecastAndValuation

from agents.report_common import _validate_and_clean_data, build_correlation_results

logger = logging.getLogger(__name__)


async def generate_profit_forecast_and_valuation(
    company_name: Annotated[str, "å…¬å¸åç§°"],
    year: Annotated[str, "å¹´ä»½"],
    query_engine: Any,
    model_type: Optional[str] = None
) -> Dict[str, Any]:
    """
    ç”ŸæˆæŠ•èµ„ç­–ç•¥ç« èŠ‚ï¼ˆç›¸å…³æ€§åˆ†ææ¨¡å‹ï¼‰
    
    åŒ…æ‹¬:
    1. æŒ‡æ ‡è‡ªåŠ¨è¯†åˆ«ä¸æŠ½å–
    2. è¾“å…¥å˜é‡è¡¨æ„å»º
    3. ç›¸å…³æ€§åˆ†æä¸ç»“è®ºè¾“å‡º
    
    Args:
        company_name: å…¬å¸åç§°
        year: å¹´ä»½
        query_engine: æŸ¥è¯¢å¼•æ“
    
    Returns:
        æŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰çš„ç»“æ„åŒ–æ•°æ®
    """
    try:
        logger.info(f"å¼€å§‹ç”ŸæˆæŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰: {company_name} {year}å¹´")
        
        # å…ˆæ£€ç´¢è¡¨æ ¼ï¼Œå†æ£€ç´¢å¹´æŠ¥æ–‡æœ¬ï¼ˆåŒä¸€ä»½å¹´æŠ¥ï¼‰
        table_query = (
            f"{company_name} {year}å¹´ å…³é”®æŒ‡æ ‡ è¡¨æ ¼ ä¸»è¦æŒ‡æ ‡ è¡¨ "
            "è‚¡æ¯ç‡ åˆ†çº¢ç‡ å¸‚å‡€ç‡ PB ROE å‡€æ¯å·® NIM éæ¯æ”¶å…¥ "
            "ä¸è‰¯è´·æ¬¾ç‡ æ ¸å¿ƒä¸€çº§èµ„æœ¬å……è¶³ç‡ æ‹¨å¤‡è¦†ç›–ç‡ "
            "é›¶å”®è´·æ¬¾å¢é€Ÿ å¯¹å…¬æ–°å…´è¡Œä¸šè´·æ¬¾å¢é€Ÿ æˆ¿åœ°äº§æ•å£ä¸è‰¯ç‡ é£é™©åŠ æƒèµ„äº§"
        )
        report_query = (
            f"{company_name} {year}å¹´ å¹´æŠ¥ ç®¡ç†å±‚è®¨è®ºä¸åˆ†æ è´¢åŠ¡æŒ‡æ ‡ ç»è¥åˆ†æ "
            "è‚¡æ¯ç‡ åˆ†çº¢ç‡ å¸‚å‡€ç‡ PB ROE å‡€æ¯å·® NIM éæ¯æ”¶å…¥å¢é€Ÿ "
            "ä¸è‰¯è´·æ¬¾ç‡ æ ¸å¿ƒä¸€çº§èµ„æœ¬å……è¶³ç‡ æ‹¨å¤‡è¦†ç›–ç‡ "
            "é›¶å”®è´·æ¬¾å¢é€Ÿ å¯¹å…¬æ–°å…´è¡Œä¸šè´·æ¬¾å¢é€Ÿ æˆ¿åœ°äº§æ•å£ä¸è‰¯ç‡"
        )
        table_data = query_engine.query(table_query)
        report_data = query_engine.query(report_query)
        forecast_data = f"ã€è¡¨æ ¼ã€‘\n{str(table_data)}\n\nã€å¹´æŠ¥æ–‡æœ¬ã€‘\n{str(report_data)}"
        
        # ä½¿ç”¨ LLM ç”Ÿæˆç»“æ„åŒ–çš„æŠ•èµ„ç­–ç•¥
        llm = Settings.llm
        normalized_model = (model_type or "all").lower()
        if normalized_model not in {"correlation", "clustering", "all"}:
            normalized_model = "all"

        prompt = f"""
ä½œä¸ºèµ„æ·±æŠ•èµ„åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®ï¼Œä¸º{company_name}ç”Ÿæˆâ€œæŠ•èµ„ç­–ç•¥-ç›¸å…³æ€§åˆ†ææ¨¡å‹â€ã€‚

## æ•°æ®æ¥æº
ä»¥ä¸‹æ•°æ®æ¥è‡ªå¹´æŠ¥æŠ«éœ²ä¸ç›¸å…³æŒ‡æ ‡è¯´æ˜ï¼š

{str(forecast_data)}

## åˆ†æè¦æ±‚
è¯·åªå®Œæˆâ€œæŒ‡æ ‡æŠ½å–ä¸ç»“æ„åŒ–â€ï¼Œä¸è¦è®¡ç®—ç›¸å…³æ€§ï¼Œä¹Ÿä¸è¦å†™æŠ•èµ„ç­–ç•¥ç»“è®ºï¼š

### 1. æŒ‡æ ‡è‡ªåŠ¨è¯†åˆ«ä¸æŠ½å–ï¼ˆä¸¥æ ¼å£å¾„ï¼‰
ä»…å…è®¸è¯†åˆ«å¹¶æŠ½å–ä»¥ä¸‹æŒ‡æ ‡ï¼ˆåç§°å¿…é¡»ä¸ä¸‹åˆ—ä¸€è‡´ï¼Œä¸è¦æ‰©å±•æˆ–æ”¹å†™ï¼‰ï¼š
- æ”¶ç›Šç±»ï¼ˆå› å˜é‡ï¼‰ï¼šçŸ­æœŸæ”¶ç›Šï¼ˆè‚¡æ¯é©±åŠ¨ï¼‰ã€é•¿æœŸæ”¶ç›Šï¼ˆç›ˆåˆ©é©±åŠ¨ï¼‰
- ç›ˆåˆ©ç±»ï¼ˆè‡ªå˜é‡ï¼‰ï¼šå‡€æ¯å·®ï¼ˆNIMï¼‰ã€éæ¯æ”¶å…¥å¢é€Ÿ
- é£é™©ç±»ï¼ˆè‡ªå˜é‡ï¼‰ï¼šè¿˜åŸåä¸è‰¯è´·æ¬¾ç‡ã€æ ¸å¿ƒä¸€çº§èµ„æœ¬å……è¶³ç‡ã€æ‹¨å¤‡è¦†ç›–ç‡
- ä¸šåŠ¡ç±»ï¼ˆè‡ªå˜é‡ï¼‰ï¼šé›¶å”®è´·æ¬¾å¢é€Ÿã€å¯¹å…¬æ–°å…´è¡Œä¸šè´·æ¬¾å¢é€Ÿ
- ä¼°å€¼ç±»ï¼ˆè‡ªå˜é‡ï¼‰ï¼šå¸‚å‡€ç‡ï¼ˆPBï¼‰ã€åˆ†çº¢ç‡
- é£é™©æ•å£ç±»ï¼ˆè‡ªå˜é‡ï¼‰ï¼šæˆ¿åœ°äº§æ•å£ä¸è‰¯ç‡

è¾“å‡ºæ¯ä¸ªæŒ‡æ ‡çš„åˆ†ç±»ã€å˜é‡è§’è‰²ï¼ˆå› å˜é‡/è‡ªå˜é‡ï¼‰ã€å–å€¼ã€å•ä½ã€æœŸé—´å’Œæ¥æºç‰‡æ®µã€‚

### 2. è¾“å…¥å˜é‡è¡¨
- å°†æŒ‡æ ‡æ•´ç†ä¸ºâ€œè¾“å…¥å˜é‡è¡¨â€ï¼ˆå˜é‡ç±»å‹ã€å…·ä½“æŒ‡æ ‡ã€å–å€¼ã€æœŸé—´ã€å•ä½ï¼‰
- ä»…ä½¿ç”¨æœ¬å¹´æŠ¥ä¸­çš„æ•°æ®ï¼›è‹¥è¡¨æ ¼å†…å­˜åœ¨å¤šä¸ªå¹´ä»½åˆ—ï¼Œè¯·ä¸€å¹¶æŠ½å–å¹¶æ ‡æ³¨period

### 3. ç›¸å…³æ€§ä¸ç»“è®ºï¼ˆä¸è¦ç”Ÿæˆï¼‰
- "correlation_results"å¿…é¡»è¾“å‡ºç©ºæ•°ç»„[]
- "strategy_conclusion"ä¸­çš„å­—æ®µä¿æŒä¸ºç©ºå­—ç¬¦ä¸²æˆ–ç©ºæ•°ç»„

### 4. æ¨¡å‹é€‰æ‹©çº¦æŸï¼ˆç”±åç«¯æ§åˆ¶ï¼‰
- model_type=correlationï¼šåªåšç›¸å…³æ€§åˆ†æï¼Œä¸ç”Ÿæˆèšç±»æ¨¡å‹
- model_type=clusteringï¼šåªåšèšç±»æ¨¡å‹ï¼Œä¸ç”Ÿæˆç›¸å…³æ€§ç»“æœ
- model_type=allï¼šç›¸å…³æ€§ä¸èšç±»æ¨¡å‹å‡å¯ç”Ÿæˆ

## âš ï¸ ä¸¥æ ¼è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰
ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œä¸”ä»…è¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚

### JSONæ ¼å¼è¦æ±‚ï¼š
1. å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥è¢«JSON.parse()è§£æ
2. ä¸è¦ä½¿ç”¨markdownä»£ç å—ï¼ˆä¸è¦ç”¨```jsonåŒ…è£¹ï¼‰
3. ä¸è¦æœ‰ä»»ä½•å‰ç¼€æˆ–åç¼€æ–‡å­—
4. ç›´æ¥è¾“å‡ºJSONå¯¹è±¡ï¼Œä»{{å¼€å§‹ï¼Œä»¥}}ç»“æŸ
5. æ‰€æœ‰å­—ç¬¦ä¸²å€¼å¿…é¡»ç”¨åŒå¼•å·åŒ…è£¹
6. æ‰€æœ‰æ•°å­—å’Œå¸ƒå°”å€¼ä¸è¦ç”¨å¼•å·
7. ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨

### JSONç»“æ„ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªï¼‰ï¼š
{{
  "indicator_extraction": [
    {{
      "name": "æŒ‡æ ‡åç§°",
      "category": "æ”¶ç›Šç±»/ç›ˆåˆ©ç±»/é£é™©ç±»/ä¸šåŠ¡ç±»/ä¼°å€¼ç±»/é£é™©æ•å£ç±»/å…¶ä»–",
      "variable_role": "å› å˜é‡/è‡ªå˜é‡",
      "value": "æŒ‡æ ‡å–å€¼",
      "unit": "%",
      "period": "2024",
      "source_excerpt": "æ¥æºç‰‡æ®µ"
    }}
  ],
  "variable_table": [
    {{
      "variable_type": "æ”¶ç›Šç±»ï¼ˆå› å˜é‡ï¼‰",
      "metric": "è‚¡æ¯ç‡",
      "value": "5.1",
      "period": "2024",
      "unit": "%"
    }}
  ],
  "correlation_results": [],
  "strategy_conclusion": {{
    "short_term": "",
    "long_term": "",
    "risk_control": "",
    "key_signals": []
  }},
  "data_sufficiency": {{
    "is_sufficient": false,
    "reason": null,
    "sample_description": null
  }},
  "notes": "è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰"
}}

### é‡è¦æç¤ºï¼š
- å¦‚æœæ•°æ®ç¼ºå¤±ï¼Œä½¿ç”¨nullæˆ–ç©ºæ•°ç»„[]
- æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å­˜åœ¨ï¼Œä¸èƒ½çœç•¥
- correlation_resultså¿…é¡»ä¿æŒç©ºæ•°ç»„[]
- ç›´æ¥è¾“å‡ºä¸Šè¿°JSONç»“æ„ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹
"""

        # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º - æ·»åŠ å¼‚å¸¸å¤„ç†å’Œæ€§èƒ½ç›‘æ§
        response = None
        import time
        structured_llm_start = time.time()
        try:
            sllm = llm.as_structured_llm(ProfitForecastAndValuation)
            raw_response = await sllm.achat([
                ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆ,æ“…é•¿ç›¸å…³æ€§åˆ†æä¸æŠ•èµ„ç­–ç•¥ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"),
                ChatMessage(role="user", content=prompt)
            ])
            
            # æ£€æŸ¥å“åº”ç±»å‹ - å¤„ç†å­—ç¬¦ä¸²å“åº”
            if isinstance(raw_response, str):
                logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] ç»“æ„åŒ–LLMè¿”å›å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æJSON")
                import json
                import re
                json_match = re.search(r'\{[\s\S]*\}', raw_response)
                if json_match:
                    parsed_data = json.loads(json_match.group(0))
                    if 'investment_strategy' in parsed_data or 'profit_forecast_and_valuation' in parsed_data:
                        parsed_data = parsed_data.get('investment_strategy') or parsed_data.get('profit_forecast_and_valuation') or parsed_data
                    response = ProfitForecastAndValuation(**parsed_data) if isinstance(parsed_data, dict) and 'indicator_extraction' in parsed_data else parsed_data
                else:
                    raise ValueError("æ— æ³•ä»å­—ç¬¦ä¸²å“åº”æå–JSON")
            elif isinstance(raw_response, ProfitForecastAndValuation):
                response = raw_response
            elif hasattr(raw_response, 'message') and hasattr(raw_response.message, 'content'):
                # å¤„ç†Responseå¯¹è±¡ï¼Œmessage.contentå¯èƒ½æ˜¯å­—ç¬¦ä¸²
                content = raw_response.message.content
                if isinstance(content, str):
                    logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] å“åº”message.contentæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æJSON")
                    import json
                    import re
                    json_match = re.search(r'\{[\s\S]*\}', content)
                    if json_match:
                        parsed_data = json.loads(json_match.group(0))
                        if 'investment_strategy' in parsed_data or 'profit_forecast_and_valuation' in parsed_data:
                            parsed_data = parsed_data.get('investment_strategy') or parsed_data.get('profit_forecast_and_valuation') or parsed_data
                        response = ProfitForecastAndValuation(**parsed_data) if isinstance(parsed_data, dict) and 'indicator_extraction' in parsed_data else parsed_data
                    else:
                        raise ValueError("æ— æ³•ä»message.contentæå–JSON")
                else:
                    response = content
            else:
                response = raw_response
            
            structured_llm_time = time.time() - structured_llm_start
            logger.info(f"âœ… [generate_profit_forecast_and_valuation] ç»“æ„åŒ–è¾“å‡ºæˆåŠŸï¼Œè€—æ—¶: {structured_llm_time:.2f}ç§’")
        except (AttributeError, ValueError, TypeError) as structured_error:
            error_type = type(structured_error).__name__
            error_msg = str(structured_error)
            structured_llm_time = time.time() - structured_llm_start
            
            # æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            if "model_dump_json" in error_msg or "AttributeError" in error_type:
                logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] ç»“æ„åŒ–LLMè¿”å›äº†å­—ç¬¦ä¸²è€ŒéPydanticæ¨¡å‹ï¼ˆè€—æ—¶: {structured_llm_time:.2f}ç§’ï¼‰")
                logger.warning(f"[generate_profit_forecast_and_valuation] é”™è¯¯ç±»å‹: {error_type}, é”™è¯¯ä¿¡æ¯: {error_msg}")
                logger.info(f"[generate_profit_forecast_and_valuation] è¿™æ˜¯LlamaIndexçš„å·²çŸ¥é—®é¢˜ï¼Œå°†å°è¯•ä»å­—ç¬¦ä¸²è§£æJSON")
            else:
                logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] ç»“æ„åŒ–è¾“å‡ºå¤±è´¥ï¼ˆ{error_type}ï¼Œè€—æ—¶: {structured_llm_time:.2f}ç§’ï¼‰: {error_msg}")
            
            logger.info(f"[generate_profit_forecast_and_valuation] å°è¯•ä½¿ç”¨æ™®é€šLLMè¾“å‡ºå¹¶æ‰‹åŠ¨è§£æJSON")
            # å›é€€åˆ°æ™®é€šLLMè¾“å‡º
            try:
                normal_response = await llm.achat([
                    ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆ,æ“…é•¿ç›¸å…³æ€§åˆ†æä¸æŠ•èµ„ç­–ç•¥ã€‚ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„JSONæ ¼å¼è¾“å‡ºï¼Œåªè¾“å‡ºJSONï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"),
                    ChatMessage(role="user", content=prompt)
                ])
                
                # æå–å¹¶è§£æJSON
                if hasattr(normal_response, 'message'):
                    content = normal_response.message.content if hasattr(normal_response.message, 'content') else str(normal_response.message)
                else:
                    content = str(normal_response)
                
                import json
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    json_str = json_match.group(0)
                    parsed_data = json.loads(json_str)
                    
                    # å¤„ç†åµŒå¥—ç»“æ„
                    if 'investment_strategy' in parsed_data or 'profit_forecast_and_valuation' in parsed_data:
                        parsed_data = parsed_data.get('investment_strategy') or parsed_data.get('profit_forecast_and_valuation') or parsed_data
                    elif len(parsed_data) == 1:
                        parsed_data = list(parsed_data.values())[0]
                    
                    try:
                        response = ProfitForecastAndValuation(**parsed_data)
                        logger.info(f"âœ… æ‰‹åŠ¨è§£æJSONæˆåŠŸ")
                    except Exception as validation_error:
                        logger.warning(f"âš ï¸ JSONéªŒè¯å¤±è´¥ï¼Œè¿”å›éƒ¨åˆ†æ•°æ®: {str(validation_error)}")
                        response = parsed_data if isinstance(parsed_data, dict) else {"content": content}
                else:
                    raise ValueError("æ— æ³•ä»å“åº”ä¸­æå–JSON")
            except Exception as fallback_error:
                logger.error(f"âŒ å›é€€æ–¹æ¡ˆä¹Ÿå¤±è´¥: {str(fallback_error)}")
                response = {
                    "error": f"ç”Ÿæˆå¤±è´¥: {str(fallback_error)}",
                    "content": content if 'content' in locals() else str(fallback_error)
                }

        logger.info(f"âœ… æŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰ç”ŸæˆæˆåŠŸ")
        
        # å¤„ç†å“åº” - ç¡®ä¿è¿”å›å­—å…¸æ ¼å¼
        result_dict = None
        
        # å¦‚æœresponseæ˜¯å­—å…¸ä¸”åŒ…å«errorï¼Œç›´æ¥è¿”å›
        if isinstance(response, dict) and 'error' in response:
            result_dict = response
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯Pydanticæ¨¡å‹
        elif isinstance(response, ProfitForecastAndValuation):
            result_dict = response.model_dump()
        elif hasattr(response, 'raw'):
            raw_data = response.raw
            if hasattr(raw_data, 'model_dump'):
                try:
                    result_dict = raw_data.model_dump()
                except Exception as e:
                    logger.warning(f"model_dump() å¤±è´¥: {e}")
            elif isinstance(raw_data, dict):
                result_dict = raw_data
            elif isinstance(raw_data, str):
                import json
                try:
                    result_dict = json.loads(raw_data)
                except json.JSONDecodeError:
                    result_dict = {"content": raw_data}
            else:
                result_dict = {"content": str(raw_data)}
        
        if result_dict is None:
            if hasattr(response, 'model_dump'):
                try:
                    result_dict = response.model_dump()
                except Exception:
                    pass
            elif isinstance(response, dict):
                result_dict = response
            else:
                result_dict = {"content": str(response)}
        
        if not isinstance(result_dict, dict):
            result_dict = {"content": str(result_dict)}
        
        result_dict["company_name"] = company_name
        result_dict["year"] = year
        
        # æ•°æ®éªŒè¯å’Œæ¸…ç†
        result_dict = _validate_and_clean_data(result_dict, ProfitForecastAndValuation)
        if isinstance(result_dict, dict):
            data_sufficiency = result_dict.get("data_sufficiency")
            if isinstance(data_sufficiency, dict) and not isinstance(data_sufficiency.get("is_sufficient"), bool):
                data_sufficiency["is_sufficient"] = False

        # ä½¿ç”¨ä»£ç è®¡ç®—ç›¸å…³æ€§ï¼ˆä¼˜å…ˆäºLLMå¡«å……ï¼‰
        if isinstance(result_dict, dict):
            if normalized_model in {"correlation", "all"}:
                correlation_results = result_dict.get("correlation_results") or []
                data_sufficiency = result_dict.get("data_sufficiency")
                if not correlation_results:
                    computed_results, computed_sufficiency = build_correlation_results(
                        result_dict.get("indicator_extraction") or [],
                        result_dict.get("variable_table") or [],
                        year
                    )
                    result_dict["correlation_results"] = computed_results
                    result_dict["data_sufficiency"] = data_sufficiency or computed_sufficiency
                elif not data_sufficiency:
                    _, computed_sufficiency = build_correlation_results(
                        result_dict.get("indicator_extraction") or [],
                        result_dict.get("variable_table") or [],
                        year
                    )
                    result_dict["data_sufficiency"] = computed_sufficiency

                # åŸºäºè®¡ç®—ç»“æœç”Ÿæˆæ´å¯Ÿï¼ˆåªåšç»“è®ºï¼Œä¸å†ç”Ÿæˆæ•°å€¼ï¼‰
                strategy_conclusion = result_dict.get("strategy_conclusion") or {}
                has_conclusion = any([
                    bool(strategy_conclusion.get("short_term")),
                    bool(strategy_conclusion.get("long_term")),
                    bool(strategy_conclusion.get("risk_control")),
                    bool(strategy_conclusion.get("key_signals"))
                ])
                if not has_conclusion:
                    import json
                    insight_prompt = f"""
ä½ æ˜¯ä¸“ä¸šæŠ•èµ„åˆ†æå¸ˆï¼Œè¯·ä»…åŸºäºç»™å®šçš„ç›¸å…³æ€§ç»“æœä¸æ•°æ®å……åˆ†æ€§è¯´æ˜ï¼Œç”ŸæˆæŠ•èµ„ç­–ç•¥ç»“è®ºã€‚
ä¸å¾—æ–°å¢æˆ–ç¼–é€ ä»»ä½•æ•°å€¼ï¼Œä¸å¾—è™šæ„ç›¸å…³ç³»æ•°ã€‚

### ç›¸å…³æ€§ç»“æœ
{json.dumps(result_dict.get("correlation_results") or [], ensure_ascii=False)}

### æ•°æ®å……åˆ†æ€§
{json.dumps(result_dict.get("data_sufficiency") or {}, ensure_ascii=False)}

### è¾“å…¥å˜é‡è¡¨ï¼ˆä¾›å‘½åå‚è€ƒï¼‰
{json.dumps(result_dict.get("variable_table") or [], ensure_ascii=False)}

### è¾“å‡ºè¦æ±‚
å¿…é¡»è¾“å‡ºJSONä¸”åªè¾“å‡ºJSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
{{
  "strategy_conclusion": {{
    "short_term": "çŸ­æœŸé…ç½®ç»“è®º",
    "long_term": "é•¿æœŸé…ç½®ç»“è®º",
    "risk_control": "é£é™©ç®¡æ§ç»“è®º",
    "key_signals": ["å…³é”®ä¿¡å·1", "å…³é”®ä¿¡å·2"]
  }},
  "notes": "è¡¥å……è¯´æ˜ï¼ˆå¯é€‰ï¼‰"
}}
"""
                    try:
                        insight_response = await llm.achat([
                            ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆï¼Œæ“…é•¿ç›¸å…³æ€§åˆ†æåçš„ç­–ç•¥æ€»ç»“ã€‚ä½ å¿…é¡»åªè¾“å‡ºJSONã€‚"),
                            ChatMessage(role="user", content=insight_prompt)
                        ])
                        if hasattr(insight_response, 'message'):
                            insight_content = insight_response.message.content if hasattr(insight_response.message, 'content') else str(insight_response.message)
                        else:
                            insight_content = str(insight_response)
                        import re
                        json_match = re.search(r'\{[\s\S]*\}', insight_content)
                        if json_match:
                            parsed = json.loads(json_match.group(0))
                            conclusion = parsed.get("strategy_conclusion") if isinstance(parsed, dict) else None
                            if isinstance(conclusion, dict):
                                result_dict["strategy_conclusion"] = {
                                    "short_term": conclusion.get("short_term") or "",
                                    "long_term": conclusion.get("long_term") or "",
                                    "risk_control": conclusion.get("risk_control") or "",
                                    "key_signals": conclusion.get("key_signals") or []
                                }
                            if isinstance(parsed, dict) and parsed.get("notes"):
                                result_dict["notes"] = parsed.get("notes")
                    except Exception as insight_error:
                        logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] æ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(insight_error)}")
            else:
                result_dict["correlation_results"] = []
                result_dict["strategy_conclusion"] = {
                    "short_term": "",
                    "long_term": "",
                    "risk_control": "",
                    "key_signals": []
                }
                result_dict["data_sufficiency"] = {
                    "is_sufficient": False,
                    "reason": "ç›¸å…³æ€§æ¨¡å‹æœªå¯ç”¨",
                    "sample_description": None
                }

            # ç”Ÿæˆèšç±»åˆ†ææ¨¡å‹ï¼ˆä»è¡¨æ ¼+å¹´æŠ¥æ–‡æœ¬è‡ªåŠ¨å¡«å……ï¼‰
            if normalized_model in {"clustering", "all"} and not result_dict.get("clustering_model"):
                import json
                clustering_prompt = f"""
ä½ æ˜¯ä¸“ä¸šæŠ•ç ”åˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆâ€œèšç±»åˆ†ææ¨¡å‹ï¼ˆå®¢ç¾¤-æ ‡çš„é€‚é…åˆ†ç»„ï¼‰â€ã€‚
ä»…ä½¿ç”¨æä¾›çš„æ•°æ®ï¼Œä¸è¦ç¼–é€ ï¼›ç¼ºå¤±å¤„ç”¨nullæˆ–ç©ºå­—ç¬¦ä¸²ã€‚

### æ•°æ®æ¥æºï¼ˆè¡¨æ ¼ä¼˜å…ˆï¼Œå…¶æ¬¡å¹´æŠ¥æ–‡æœ¬ï¼‰
{str(forecast_data)}

### å¿…é¡»åŒ…å«çš„å˜é‡è®¾è®¡ï¼ˆç»´åº¦ä¸æŒ‡æ ‡åç§°å¿…é¡»ä¸€è‡´ï¼‰
- ä¼°å€¼ç»´åº¦ï¼šå¸‚å‡€ç‡ï¼ˆPBï¼‰
- ç›ˆåˆ©ç»´åº¦ï¼šåŠ æƒå¹³å‡ROE
- é£é™©ç»´åº¦ï¼šè¿˜åŸåä¸è‰¯è´·æ¬¾ç‡
- å¢é•¿ç»´åº¦ï¼šå¯¹å…¬è´·æ¬¾å¢é€Ÿ
- é˜²å¾¡ç»´åº¦ï¼šè‚¡æ¯ç‡

### å‚è€ƒè¡Œä¸šå¯¹æ ‡å¯¹è±¡ï¼ˆå¦‚æœ‰æŠ«éœ²ï¼‰
æ‹›è¡Œã€å…´ä¸šã€è‚¡ä»½è¡Œå‡å€¼ï¼ˆ2024å¹´ï¼‰

### èšç±»ç»“æœï¼ˆå›ºå®šK=3ï¼ŒæŒ‰åŒºé—´è§„åˆ™å½’ç±»ï¼‰
ç»„åˆ«1ï¼šé«˜è‚¡æ¯ä½ä¼°å€¼é˜²å¾¡ç»„
ç»„åˆ«2ï¼šç¨³å¥å¢é•¿ç»„
ç»„åˆ«3ï¼šé«˜å¢é•¿é«˜å¼¹æ€§ç»„

### è¾“å‡ºè¦æ±‚
å¿…é¡»è¾“å‡ºJSONä¸”åªè¾“å‡ºJSONï¼Œç»“æ„å¦‚ä¸‹ï¼š
{{
  "clustering_model": {{
    "method": "K-means",
    "k": 3,
    "variable_table": [
      {{
        "dimension": "ä¼°å€¼ç»´åº¦",
        "metric": "å¸‚å‡€ç‡ï¼ˆPBï¼‰",
        "company_value": "0.55",
        "industry_benchmark": "æ‹›è¡Œ0.82ã€å…´ä¸š0.61ã€è‚¡ä»½è¡Œå‡å€¼0.73"
      }}
    ],
    "group_results": [
      {{
        "group_name": "ç»„åˆ«1ï¼šé«˜è‚¡æ¯ä½ä¼°å€¼é˜²å¾¡ç»„",
        "feature_profile": "PB<0.6ã€è‚¡æ¯ç‡>5%ã€ROE10%-11%ã€è¿˜åŸåä¸è‰¯ç‡1.7%-1.8%",
        "company_assignment": "æ ¸å¿ƒæ ‡çš„/è¾¹ç¼˜æ ‡çš„/æš‚ä¸å½’å±",
        "investor_profile": "æ”¶ç›Šç›®æ ‡5%-8%ã€é£é™©å®¹å¿åº¦ä½ã€æµåŠ¨æ€§éœ€æ±‚ä¸­",
        "time_risk_bucket": "çŸ­æœŸï¼ˆ6-12ä¸ªæœˆï¼‰-ä½é£é™©"
      }}
    ],
    "conclusion": {{
      "current_position": "å½“å‰åˆ†ç»„ç»“è®º",
      "upgrade_conditions": "è¿›å…¥ç¨³å¥å¢é•¿ç»„æ¡ä»¶",
      "high_growth_conditions": "è¿›å…¥é«˜å¢é•¿é«˜å¼¹æ€§ç»„æ¡ä»¶"
    }}
  }}
}}
"""
                try:
                    clustering_response = await llm.achat([
                        ChatMessage(role="system", content="ä½ æ˜¯ä¸“ä¸šæŠ•ç ”åˆ†æå¸ˆï¼Œå¿…é¡»ä¸¥æ ¼è¾“å‡ºJSONã€‚"),
                        ChatMessage(role="user", content=clustering_prompt)
                    ])
                    if hasattr(clustering_response, 'message'):
                        clustering_content = clustering_response.message.content if hasattr(clustering_response.message, 'content') else str(clustering_response.message)
                    else:
                        clustering_content = str(clustering_response)
                    import re
                    json_match = re.search(r'\{[\s\S]*\}', clustering_content)
                    if json_match:
                        parsed = json.loads(json_match.group(0))
                        clustering_model = parsed.get("clustering_model") if isinstance(parsed, dict) else None
                        if isinstance(clustering_model, dict):
                            result_dict["clustering_model"] = clustering_model
                except Exception as clustering_error:
                    logger.warning(f"âš ï¸ [generate_profit_forecast_and_valuation] èšç±»æ¨¡å‹ç”Ÿæˆå¤±è´¥: {str(clustering_error)}")
        
        try:
            import json
            logger.info("ğŸ“¦ æŠ•èµ„ç­–ç•¥JSONç»“æœ:\n%s", json.dumps(result_dict, ensure_ascii=False, indent=2))
        except Exception as log_error:
            logger.warning("âš ï¸ æŠ•èµ„ç­–ç•¥JSONæ—¥å¿—è¾“å‡ºå¤±è´¥: %s", str(log_error))

        return result_dict
        
    except Exception as e:
        logger.error(f"âŒ ç”ŸæˆæŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰å¤±è´¥: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "error": f"ç”ŸæˆæŠ•èµ„ç­–ç•¥ï¼ˆç›¸å…³æ€§åˆ†æï¼‰å¤±è´¥: {str(e)}",
            "company_name": company_name,
            "year": year
        }

