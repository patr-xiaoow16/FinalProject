"""
æ–‡ä»¶ä¸Šä¼ APIæ¥å£
"""

import os
import shutil
from pathlib import Path
from typing import List, Dict, Any
from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse, FileResponse, Response
import logging
import urllib.parse

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/upload", tags=["upload"])

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
ALLOWED_EXTENSIONS = {'.pdf', '.xlsx', '.xls'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

@router.post("/file")
async def upload_file(file: UploadFile = File(...)):
    """
    ä¸Šä¼ å•ä¸ªæ–‡ä»¶
    
    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶
        
    Returns:
        ä¸Šä¼ ç»“æœ
    """
    try:
        # éªŒè¯æ–‡ä»¶
        if not file.filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_content = await file.read()
        if len(file_content) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=400,
                detail=f"æ–‡ä»¶è¿‡å¤§: {len(file_content)} bytesã€‚æœ€å¤§å…è®¸: {MAX_FILE_SIZE} bytes"
            )
        
        # ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
        upload_dir = Path("uploads")
        upload_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_filename = _generate_safe_filename(file.filename)
        file_path = upload_dir / safe_filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(file_content)
        
        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {safe_filename}")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
                "filename": safe_filename,
                "file_path": str(file_path),
                "file_size": len(file_content),
                "file_type": file_ext
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

@router.post("/files")
async def upload_files(files: List[UploadFile] = File(...)):
    """
    ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
    
    Args:
        files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
        
    Returns:
        ä¸Šä¼ ç»“æœåˆ—è¡¨
    """
    try:
        if not files:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰é€‰æ‹©æ–‡ä»¶")
        
        if len(files) > 10:
            raise HTTPException(status_code=400, detail="ä¸€æ¬¡æœ€å¤šä¸Šä¼ 10ä¸ªæ–‡ä»¶")
        
        results = []
        upload_dir = Path("uploads")
        upload_dir.mkdir(exist_ok=True)
        
        for file in files:
            try:
                # éªŒè¯å•ä¸ªæ–‡ä»¶
                if not file.filename:
                    results.append({
                        "filename": "unknown",
                        "status": "error",
                        "message": "æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
                    })
                    continue
                
                file_ext = Path(file.filename).suffix.lower()
                if file_ext not in ALLOWED_EXTENSIONS:
                    results.append({
                        "filename": file.filename,
                        "status": "error",
                        "message": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
                    })
                    continue
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                file_content = await file.read()
                if len(file_content) > MAX_FILE_SIZE:
                    results.append({
                        "filename": file.filename,
                        "status": "error",
                        "message": f"æ–‡ä»¶è¿‡å¤§: {len(file_content)} bytes"
                    })
                    continue
                
                # ä¿å­˜æ–‡ä»¶
                safe_filename = _generate_safe_filename(file.filename)
                file_path = upload_dir / safe_filename
                
                with open(file_path, "wb") as f:
                    f.write(file_content)
                
                results.append({
                    "filename": safe_filename,
                    "original_filename": file.filename,
                    "status": "success",
                    "file_path": str(file_path),
                    "file_size": len(file_content),
                    "file_type": file_ext
                })
                
                logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {safe_filename}")
                
            except Exception as e:
                results.append({
                    "filename": file.filename if file.filename else "unknown",
                    "status": "error",
                    "message": str(e)
                })
                logger.error(f"æ–‡ä»¶ {file.filename} ä¸Šä¼ å¤±è´¥: {str(e)}")
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r["status"] == "success")
        error_count = len(results) - success_count
        
        return JSONResponse(
            status_code=200,
            content={
                "message": f"æ‰¹é‡ä¸Šä¼ å®Œæˆ: {success_count} æˆåŠŸ, {error_count} å¤±è´¥",
                "total_files": len(results),
                "success_count": success_count,
                "error_count": error_count,
                "results": results
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")

@router.get("/list")
async def list_uploaded_files():
    """
    åˆ—å‡ºå·²ä¸Šä¼ çš„æ–‡ä»¶
    
    Returns:
        æ–‡ä»¶åˆ—è¡¨
    """
    try:
        upload_dir = Path("uploads")
        if not upload_dir.exists():
            return JSONResponse(
                status_code=200,
                content={
                    "message": "ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨",
                    "files": []
                }
            )
        
        files = []
        for file_path in upload_dir.iterdir():
            if file_path.is_file():
                file_info = {
                    "filename": file_path.name,
                    "file_path": str(file_path),
                    "file_size": file_path.stat().st_size,
                    "file_type": file_path.suffix.lower(),
                    "created_time": file_path.stat().st_ctime
                }
                files.append(file_info)
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        files.sort(key=lambda x: x["created_time"], reverse=True)
        
        return JSONResponse(
            status_code=200,
            content={
                "message": f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶",
                "total_files": len(files),
                "files": files
            }
        )
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")

@router.delete("/file/{filename}")
async def delete_file(filename: str):
    """
    åˆ é™¤æŒ‡å®šæ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶å
        
    Returns:
        åˆ é™¤ç»“æœ
    """
    try:
        upload_dir = Path("uploads")
        file_path = upload_dir / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        if not file_path.is_file():
            raise HTTPException(status_code=400, detail="ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶")
        
        # åˆ é™¤æ–‡ä»¶
        file_path.unlink()
        
        # ä»ç´¢å¼•ä¸­åˆ é™¤è¯¥æ–‡ä»¶çš„æ–‡æ¡£
        try:
            from core.rag_engine import RAGEngine
            rag_engine = RAGEngine()
            rag_engine.remove_file_from_index(filename)
        except Exception as e:
            logger.warning(f"âš ï¸ ä»ç´¢å¼•ä¸­åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
            # ä¸é˜»æ­¢æ–‡ä»¶åˆ é™¤ï¼Œåªè®°å½•è­¦å‘Š
        
        logger.info(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {filename}")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": "æ–‡ä»¶åˆ é™¤æˆåŠŸ",
                "filename": filename
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")

@router.get("/file/{filename}")
async def get_file(filename: str):
    """
    è·å–ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆç”¨äºé¢„è§ˆï¼‰
    
    Args:
        filename: æ–‡ä»¶å
    
    Returns:
        æ–‡ä»¶å†…å®¹
    """
    try:
        upload_dir = Path("uploads")
        file_path = upload_dir / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        if not file_path.is_file():
            raise HTTPException(status_code=400, detail="ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶")
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        file_ext = file_path.suffix.lower()
        if file_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹é¢„è§ˆ: {file_ext}")
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(file_path, 'rb') as f:
            file_content = f.read()
        
        # å¤„ç†ä¸­æ–‡æ–‡ä»¶å
        try:
            encoded_filename = urllib.parse.quote(filename, safe='')
            content_disposition = f"inline; filename*=UTF-8''{encoded_filename}"
        except Exception:
            content_disposition = f'inline; filename="{filename}"'
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®åª’ä½“ç±»å‹
        if file_ext == '.pdf':
            media_type = 'application/pdf'
        elif file_ext in {'.xlsx', '.xls'}:
            # Excelæ–‡ä»¶è¿”å›HTMLé¢„è§ˆé¡µé¢
            return await get_excel_preview(file_path, filename)
        else:
            media_type = 'application/octet-stream'
        
        # è¿”å›æ–‡ä»¶ï¼ˆè®¾ç½®ä¸ºinlineï¼Œåœ¨æµè§ˆå™¨ä¸­é¢„è§ˆè€Œä¸æ˜¯ä¸‹è½½ï¼‰
        return Response(
            content=file_content,
            media_type=media_type,
            headers={
                'Content-Disposition': content_disposition,
                'Content-Length': str(len(file_content))
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")

async def get_excel_preview(file_path: Path, filename: str):
    """
    è·å–Excelæ–‡ä»¶çš„HTMLé¢„è§ˆ
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        filename: æ–‡ä»¶å
    
    Returns:
        HTMLé¢„è§ˆé¡µé¢
    """
    try:
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        file_ext = file_path.suffix.lower()
        if file_ext not in {'.xlsx', '.xls'}:
            raise HTTPException(status_code=400, detail="åªæ”¯æŒExcelæ–‡ä»¶é¢„è§ˆ")
        
        # è¯»å–Excelæ–‡ä»¶å¹¶è½¬æ¢ä¸ºHTMLè¡¨æ ¼
        from core.excel_processor import ExcelProcessor
        
        excel_processor = ExcelProcessor()
        excel_data = excel_processor.process_excel_file(str(file_path), filename)
        
        # ç”ŸæˆHTMLé¢„è§ˆé¡µé¢
        html_content = generate_excel_preview_html(excel_data, filename)
        
        # å°†HTMLå†…å®¹ç¼–ç ä¸ºUTF-8å­—èŠ‚
        html_bytes = html_content.encode('utf-8')
        
        # å¤„ç†ä¸­æ–‡æ–‡ä»¶åç¼–ç 
        try:
            encoded_filename = urllib.parse.quote(filename, safe='')
            content_disposition = f'inline; filename*=UTF-8\'\'{encoded_filename}.html'
        except Exception:
            content_disposition = f'inline; filename="{filename}.html"'
        
        return Response(
            content=html_bytes,
            media_type='text/html; charset=utf-8',
            headers={
                'Content-Disposition': content_disposition,
                'Content-Length': str(len(html_bytes))
            }
        )
        
    except Exception as e:
        logger.error(f"ç”ŸæˆExcelé¢„è§ˆå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆExcelé¢„è§ˆå¤±è´¥: {str(e)}")

def generate_excel_preview_html(excel_data: Dict[str, Any], filename: str) -> str:
    """
    ç”ŸæˆExcelæ–‡ä»¶çš„HTMLé¢„è§ˆé¡µé¢
    
    Args:
        excel_data: Excelå¤„ç†ç»“æœ
        filename: æ–‡ä»¶å
    
    Returns:
        HTMLå†…å®¹
    """
    html_parts = [
        '<!DOCTYPE html>',
        '<html lang="zh-CN">',
        '<head>',
        '<meta charset="UTF-8">',
        '<meta name="viewport" content="width=device-width, initial-scale=1.0">',
        f'<title>é¢„è§ˆ - {filename}</title>',
        '<style>',
        'body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }',
        '.container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }',
        '.header { padding: 20px; border-bottom: 1px solid #e5e7eb; }',
        '.header h1 { margin: 0; font-size: 1.5rem; color: #111827; }',
        '.header .file-info { margin-top: 8px; color: #6b7280; font-size: 0.875rem; }',
        '.sheets-tabs { display: flex; gap: 8px; padding: 16px 20px; border-bottom: 1px solid #e5e7eb; background: #f9fafb; flex-wrap: wrap; }',
        '.sheet-tab { padding: 8px 16px; border: 1px solid #e5e7eb; border-radius: 6px; background: white; cursor: pointer; font-size: 0.875rem; transition: all 0.2s; }',
        '.sheet-tab:hover { border-color: #4facfe; background: #f0f9ff; }',
        '.sheet-tab.active { background: #4facfe; color: white; border-color: #4facfe; }',
        '.sheet-tab.has-statement { border-left: 3px solid #10b981; }',
        '.sheet-content { padding: 20px; display: none; }',
        '.sheet-content.active { display: block; }',
        '.statement-badge { display: inline-block; padding: 4px 8px; background: #dcfce7; color: #166534; border-radius: 4px; font-size: 0.75rem; font-weight: 500; margin-left: 8px; }',
        'table { width: 100%; border-collapse: collapse; margin-top: 16px; font-size: 0.875rem; table-layout: auto; }',
        'th, td { padding: 8px 12px; text-align: left; border: 1px solid #e5e7eb; white-space: nowrap; }',
        'th { background: #f9fafb; font-weight: 600; color: #374151; position: sticky; top: 0; z-index: 10; }',
        'tbody tr:nth-child(even) { background: #f9fafb; }',
        'tbody tr:hover { background: #f0f9ff; }',
        'td { white-space: normal; word-wrap: break-word; max-width: 200px; }',
        '.empty-sheet { text-align: center; padding: 40px; color: #9ca3af; }',
        '</style>',
        '</head>',
        '<body>',
        '<div class="container">',
        f'<div class="header">',
        f'<h1>ğŸ“Š {filename}</h1>',
        f'<div class="file-info">å·¥ä½œè¡¨æ•°: {excel_data.get("sheet_count", 0)} | è´¢åŠ¡æŠ¥è¡¨: {len(excel_data.get("financial_statements", []))}ä¸ª</div>',
        '</div>',
        '<div class="sheets-tabs">'
    ]
    
    # ç”Ÿæˆå·¥ä½œè¡¨æ ‡ç­¾
    sheet_info = excel_data.get('sheet_info', [])
    for i, sheet in enumerate(sheet_info):
        is_statement = sheet.get('is_financial_statement', False)
        statement_type = sheet.get('statement_type', '')
        statement_badge = f'<span class="statement-badge">{statement_type}</span>' if statement_type else ''
        tab_class = 'sheet-tab' + (' active' if i == 0 else '') + (' has-statement' if is_statement else '')
        html_parts.append(
            f'<div class="{tab_class}" onclick="showSheet({i})">'
            f'ğŸ“‹ {sheet.get("sheet_name", "Sheet")}{statement_badge}'
            '</div>'
        )
    
    html_parts.append('</div>')
    
    # ç”Ÿæˆå·¥ä½œè¡¨å†…å®¹
    documents = excel_data.get('documents', [])
    if not documents:
        html_parts.append('<div class="sheet-content active"><div class="empty-sheet">æ²¡æœ‰å¯æ˜¾ç¤ºçš„å·¥ä½œè¡¨</div></div>')
    else:
        for i, doc in enumerate(documents):
            # å¤„ç†Documentå¯¹è±¡æˆ–å­—å…¸
            if hasattr(doc, 'metadata'):
                metadata = doc.metadata
                text = doc.text
            elif isinstance(doc, dict):
                metadata = doc.get('metadata', {})
                text = doc.get('text', '')
            else:
                continue
            
            sheet_name = metadata.get('sheet_name', f'Sheet{i+1}')
            statement_type = metadata.get('financial_statement_type', '')
            content_class = 'sheet-content' + (' active' if i == 0 else '')
            
            html_parts.append(f'<div class="{content_class}" id="sheet-{i}">')
            
            if statement_type:
                html_parts.append(f'<div style="margin-bottom: 16px;"><span class="statement-badge">è´¢åŠ¡æŠ¥è¡¨ç±»å‹: {statement_type}</span></div>')
            
            # è§£ææ–‡æœ¬å†…å®¹ä¸ºè¡¨æ ¼
            table_html = parse_text_to_table(text)
            html_parts.append(table_html)
            
            html_parts.append('</div>')
    
    html_parts.extend([
        '</div>',
        '<script>',
        'function showSheet(index) {',
        '  document.querySelectorAll(".sheet-tab").forEach((tab, i) => {',
        '    tab.classList.toggle("active", i === index);',
        '  });',
        '  document.querySelectorAll(".sheet-content").forEach((content, i) => {',
        '    content.classList.toggle("active", i === index);',
        '  });',
        '}',
        '</script>',
        '</body>',
        '</html>'
    ])
    
    return '\n'.join(html_parts)

def parse_text_to_table(text: str) -> str:
    """
    å°†æ–‡æœ¬å†…å®¹è§£æä¸ºHTMLè¡¨æ ¼
    ä»ExcelProcessorç”Ÿæˆçš„æ–‡æœ¬æ ¼å¼ä¸­æå–è¡¨æ ¼æ•°æ®
    æ”¯æŒå¤šè¡Œè¡¨å¤´ï¼ˆå¦‚ç¬¬ä¸€è¡Œæ˜¯é¡¹ç›®åï¼Œç¬¬äºŒè¡Œæ˜¯æ—¥æœŸï¼‰
    
    Args:
        text: æ–‡æ¡£æ–‡æœ¬å†…å®¹ï¼ˆåŒ…å« | åˆ†éš”çš„è¡¨æ ¼è¡Œï¼‰
    
    Returns:
        HTMLè¡¨æ ¼å­—ç¬¦ä¸²
    """
    import html as html_escape
    
    lines = text.split('\n')
    table_rows = []
    in_table = False
    separator_found = False
    
    logger.info(f"è§£æè¡¨æ ¼æ–‡æœ¬: æ€»è¡Œæ•°={len(lines)}")
    
    for line in lines:
        line = line.strip()
        # è·³è¿‡æ ‡é¢˜å’Œç©ºè¡Œ
        if not line or line.startswith('ã€') or line.startswith('å·¥ä½œè¡¨:') or line.startswith('è¡¨æ ¼å†…å®¹'):
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œï¼ˆåŒ…å« | åˆ†éš”ç¬¦ï¼‰
        if '|' in line:
            in_table = True
            # åˆ†å‰²å•å…ƒæ ¼ - ä½¿ç”¨ | ä½œä¸ºåˆ†éš”ç¬¦
            # æ³¨æ„ï¼šå¦‚æœæ–‡æœ¬æ˜¯ "col1 | col2 | col3"ï¼Œsplit('|') ä¼šå¾—åˆ° ['col1 ', ' col2 ', ' col3']
            cells = [cell.strip() for cell in line.split('|')]
            
            # è°ƒè¯•ï¼šè®°å½•åŸå§‹åˆ†å‰²ç»“æœ
            if len(table_rows) < 3:
                logger.info(f"  åŸå§‹è¡Œåˆ†å‰²: åˆ†éš”ç¬¦æ•°é‡={line.count('|')}, åˆ†å‰²åå•å…ƒæ ¼æ•°={len(cells)}")
                logger.info(f"  åŸå§‹è¡Œå†…å®¹: {line[:200]}")
            
            # ç§»é™¤é¦–å°¾ç©ºå…ƒç´ ï¼ˆé€šå¸¸ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ˜¯ç©ºçš„ï¼Œå› ä¸º | åœ¨å¼€å¤´å’Œç»“å°¾ï¼‰
            # ä½†ä¿ç•™ä¸­é—´çš„æ‰€æœ‰å•å…ƒæ ¼ï¼ŒåŒ…æ‹¬ç©ºå•å…ƒæ ¼
            if len(cells) > 2:
                cells = cells[1:-1]  # ç§»é™¤é¦–å°¾ç©ºå…ƒç´ 
            elif len(cells) == 2:
                # å¦‚æœåªæœ‰2ä¸ªå…ƒç´ ï¼Œå¯èƒ½æ˜¯ |cell| æˆ– | | çš„æƒ…å†µ
                # ä¿ç•™ä¸¤ä¸ªå…ƒç´ ï¼Œå³ä½¿å…¶ä¸­ä¸€ä¸ªä¸ºç©º
                cells = [cells[0], cells[1]]
            elif len(cells) == 1:
                # å¦‚æœåªæœ‰1ä¸ªå…ƒç´ ï¼Œå¯èƒ½æ˜¯æ•´è¡Œæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œæˆ–è€…æ ¼å¼å¼‚å¸¸
                # ä½†ä»ç„¶ä¿ç•™è¿™ä¸€è¡Œï¼Œä¸è¦è·³è¿‡
                if line.count('|') > 0:
                    logger.warning(f"  è­¦å‘Šï¼šè¡ŒåŒ…å«{line.count('|')}ä¸ª'|'ä½†åˆ†å‰²ååªæœ‰1ä¸ªå…ƒç´ : {line[:100]}")
                # ä¿ç•™è¿™ä¸ªå•å…ƒæ ¼
                pass
            
            # ä¿ç•™æ‰€æœ‰è¡Œï¼Œå³ä½¿æŸäº›å•å…ƒæ ¼ä¸ºç©ºï¼ˆå› ä¸ºç©ºå•å…ƒæ ¼ä¹Ÿå¯èƒ½ä»£è¡¨åˆ—ï¼‰
            # åªè¦cellsä¸ä¸ºç©ºåˆ—è¡¨ï¼Œå°±æ·»åŠ 
            if cells is not None and len(cells) > 0:
                table_rows.append(cells)
                # è°ƒè¯•ï¼šæ£€æŸ¥å‰å‡ è¡Œæ˜¯å¦åŒ…å«241231å’Œ250930
                if len(table_rows) <= 3:
                    row_text = ' '.join([str(cell) for cell in cells if cell])
                    logger.info(f"  è§£æè¡Œ{len(table_rows)}: åˆ—æ•°={len(cells)}, å‰5åˆ—={cells[:5]}")
                    if '241231' in row_text:
                        logger.info(f"  âœ… è§£æè¡Œ{len(table_rows)}åŒ…å«241231: {cells[:10]}")
                    if '250930' in row_text:
                        logger.info(f"  âœ… è§£æè¡Œ{len(table_rows)}åŒ…å«250930: {cells[:10]}")
        elif in_table and ('---' in line or line.startswith('-')):
            # åˆ†éš”çº¿ï¼Œæ ‡è®°è¡¨å¤´ç»“æŸ
            separator_found = True
            continue
        elif in_table and not ('|' in line):
            # è¡¨æ ¼ç»“æŸï¼ˆå¦‚æœé‡åˆ°éè¡¨æ ¼è¡Œä¸”å·²æœ‰æ•°æ®ï¼‰
            if len(table_rows) > 0:
                break
    
    if not table_rows:
        return '<div class="empty-sheet">æ­¤å·¥ä½œè¡¨ä¸ºç©ºæˆ–æ— æ³•è§£æä¸ºè¡¨æ ¼</div>'
    
    logger.info(f"è§£æå®Œæˆ: è¡¨æ ¼è¡Œæ•°={len(table_rows)}")
    if table_rows:
        logger.info(f"  ç¬¬ä¸€è¡Œåˆ—æ•°={len(table_rows[0])}, å†…å®¹å‰10åˆ—={table_rows[0][:10]}")
        if len(table_rows) > 1:
            logger.info(f"  ç¬¬äºŒè¡Œåˆ—æ•°={len(table_rows[1])}, å†…å®¹å‰10åˆ—={table_rows[1][:10]}")
    
    # ç¡®å®šè¡¨å¤´è¡Œæ•°
    # æ£€æŸ¥å‰ä¸¤è¡Œï¼šå¦‚æœç¬¬äºŒè¡Œçœ‹èµ·æ¥åƒæ—¥æœŸè¡Œï¼ˆåŒ…å«6ä½æ•°å­—ï¼‰ï¼Œåˆ™ä¸¤è¡Œéƒ½æ˜¯è¡¨å¤´
    header_row_count = 1
    if len(table_rows) > 1:
        second_row = table_rows[1]
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ ¼å¼ï¼ˆ6ä½æ•°å­—ï¼Œå¦‚250930ã€241231ï¼‰
        has_date_format = any(
            (str(cell).isdigit() and len(str(cell)) == 6) or
            'å¹´' in str(cell) or 'æœˆ' in str(cell) or 'æ—¥' in str(cell) or
            'æœŸæœ«' in str(cell) or 'æœŸåˆ' in str(cell) or
            'ä½™é¢' in str(cell)
            for cell in second_row if cell and str(cell).strip()
        )
        # æ£€æŸ¥ç¬¬äºŒè¡Œæ˜¯å¦ä¸ç¬¬ä¸€è¡Œåˆ—æ•°ç›¸åŒï¼ˆé€šå¸¸æ˜¯è¡¨å¤´çš„ç‰¹å¾ï¼‰
        # å¹¶ä¸”ç¬¬ä¸€è¡Œé€šå¸¸åŒ…å«"é¡¹ç›®"ã€"ç§‘ç›®"ç­‰å…³é”®è¯
        first_row_has_header_keywords = any(
            'é¡¹ç›®' in str(cell) or 'ç§‘ç›®' in str(cell) or 'item' in str(cell).lower()
            for cell in table_rows[0] if cell and str(cell).strip()
        )
        if has_date_format and len(second_row) == len(table_rows[0]) and first_row_has_header_keywords:
            header_row_count = 2
    
    # ç”ŸæˆHTMLè¡¨æ ¼
    html = ['<div style="overflow-x: auto; max-height: 600px; overflow-y: auto;">', '<table style="width: 100%; border-collapse: collapse;">']
    
    # ç¡®å®šæœ€å¤§åˆ—æ•°ï¼ˆç”¨äºå¯¹é½ï¼‰- ä½¿ç”¨æ‰€æœ‰è¡Œçš„æœ€å¤§åˆ—æ•°
    max_cols = max(len(row) for row in table_rows) if table_rows else 0
    logger.info(f"HTMLç”Ÿæˆ: header_row_count={header_row_count}, max_cols={max_cols}")
    
    # æ£€æŸ¥è¡¨å¤´æ˜¯å¦åŒ…å«241231å’Œ250930
    if table_rows and len(table_rows) > 0:
        for i in range(min(header_row_count, len(table_rows))):
            header_text = ' '.join([str(cell) for cell in table_rows[i] if cell])
            if '241231' in header_text:
                logger.info(f"  âœ… HTMLè¡¨å¤´è¡Œ{i}åŒ…å«241231")
            if '250930' in header_text:
                logger.info(f"  âœ… HTMLè¡¨å¤´è¡Œ{i}åŒ…å«250930")
    
    # ç”Ÿæˆè¡¨å¤´ï¼ˆå¯èƒ½æœ‰å¤šè¡Œï¼‰
    if table_rows:
        html.append('<thead>')
        for i in range(min(header_row_count, len(table_rows))):
            html.append('<tr>')
            header_row = table_rows[i]
            # ç¡®ä¿è¡¨å¤´è¡ŒåŒ…å«æ‰€æœ‰åˆ—
            while len(header_row) < max_cols:
                header_row.append('')
            # åªå–å‰max_colsä¸ªå…ƒç´ 
            header_row = header_row[:max_cols]
            for cell in header_row:
                # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
                cell_escaped = html_escape.escape(str(cell))
                html.append(f'<th style="padding: 8px 12px; text-align: left; border: 1px solid #e5e7eb; background: #f9fafb; font-weight: 600; position: sticky; top: 0;">{cell_escaped}</th>')
            html.append('</tr>')
        html.append('</thead>')
        html.append('<tbody>')
        
        # æ•°æ®è¡Œä»è¡¨å¤´ä¹‹åå¼€å§‹
        data_start = header_row_count
        max_rows = min(100, len(table_rows) - data_start)
        
        for i in range(data_start, min(data_start + max_rows, len(table_rows))):
            row = table_rows[i]
            html.append('<tr>')
            # ç¡®ä¿åˆ—æ•°ä¸€è‡´ï¼Œä½¿ç”¨æœ€å¤§åˆ—æ•°
            while len(row) < max_cols:
                row.append('')
            # åªå–å‰max_colsä¸ªå…ƒç´ 
            row = row[:max_cols]
            for cell in row:
                # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
                cell_escaped = html_escape.escape(str(cell))
                html.append(f'<td style="padding: 8px 12px; text-align: left; border: 1px solid #e5e7eb;">{cell_escaped}</td>')
            html.append('</tr>')
        
        if len(table_rows) > data_start + max_rows:
            html.append(f'<tr><td colspan="{max_cols}" style="text-align: center; color: #9ca3af; padding: 16px; border: 1px solid #e5e7eb;">... (å…±{len(table_rows)-header_row_count}è¡Œæ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰{max_rows}è¡Œ)</td></tr>')
        
        html.append('</tbody>')
    
    html.append('</table></div>')
    return '\n'.join(html)

@router.delete("/clear")
async def clear_uploads():
    """
    æ¸…ç©ºä¸Šä¼ ç›®å½•
    
    Returns:
        æ¸…ç©ºç»“æœ
    """
    try:
        upload_dir = Path("uploads")
        if not upload_dir.exists():
            return JSONResponse(
                status_code=200,
                content={
                    "message": "ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨",
                    "deleted_count": 0
                }
            )
        
        deleted_count = 0
        deleted_files = []
        for file_path in upload_dir.iterdir():
            if file_path.is_file():
                deleted_files.append(file_path.name)
                file_path.unlink()
                deleted_count += 1
        
        # ä»ç´¢å¼•ä¸­åˆ é™¤æ‰€æœ‰å·²åˆ é™¤æ–‡ä»¶çš„æ–‡æ¡£
        if deleted_files:
            try:
                from core.rag_engine import RAGEngine
                rag_engine = RAGEngine()
                for filename in deleted_files:
                    rag_engine.remove_file_from_index(filename)
            except Exception as e:
                logger.warning(f"âš ï¸ ä»ç´¢å¼•ä¸­åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        logger.info(f"æ¸…ç©ºä¸Šä¼ ç›®å½•: åˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶")
        
        return JSONResponse(
            status_code=200,
            content={
                "message": f"æ¸…ç©ºå®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶",
                "deleted_count": deleted_count
            }
        )
        
    except Exception as e:
        logger.error(f"æ¸…ç©ºä¸Šä¼ ç›®å½•å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºä¸Šä¼ ç›®å½•å¤±è´¥: {str(e)}")

def _generate_safe_filename(filename: str) -> str:
    """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ˆä¿ç•™åŸå§‹æ–‡ä»¶åï¼ŒåŒåæ—¶è¦†ç›–ï¼‰"""
    import os
    import re
    
    # è·å–æ–‡ä»¶åï¼ˆå»é™¤è·¯å¾„ï¼‰
    safe_name = os.path.basename(filename)
    
    # ç§»é™¤ä¸å®‰å…¨çš„å­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡å­—ç¬¦ã€æ•°å­—ã€å­—æ¯ã€è¿å­—ç¬¦ã€ä¸‹åˆ’çº¿ã€ç‚¹å’Œç©ºæ ¼
    # Windows ä¸å…è®¸çš„å­—ç¬¦: < > : " / \ | ? *
    # æ§åˆ¶å­—ç¬¦: \x00-\x1f
    safe_name = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '_', safe_name)
    
    # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
    safe_name = safe_name.strip(' .')
    
    # å¦‚æœæ–‡ä»¶åä¸ºç©ºæˆ–åªæœ‰ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not safe_name or safe_name.strip() == '':
        safe_name = 'uploaded_file.pdf'
    
    # ç¡®ä¿æ–‡ä»¶åä¸ä¸ºç©ºä¸”æœ‰æ•ˆ
    if not safe_name:
        safe_name = 'uploaded_file.pdf'
    
    return safe_name
